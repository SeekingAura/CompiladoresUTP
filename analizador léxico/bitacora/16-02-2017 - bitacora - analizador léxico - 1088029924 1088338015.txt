Estudiantes: Carlos Arturo Moreno Tabares - 1088029924
Karen Stefanny Lopez Segura - 1088338015

se verificaron las cosas pendientes, para el tema del calculo de columna, solo media bien la primera linea pero despues de esa las media mal, entonces se procedió a verificar la función de obtener # de columna, luego de varias pruebas se hizo su respectiva modificación y quedó funcionando correctamente:

parte del archivo "test lexico.py"
#--#

	# Compute column.
	#     input is the input text string
	#     token is a token instance
	def getColumn(self, text, token):
		last_cr = text.rfind('\n', 0, token.index)+1
		#print("last_cr : {}".format(last_cr))#verificando valor de indexados previos
		if last_cr < 0:
			last_cr = 0
		column = (token.index - last_cr) + 1
		return column

#--#

lo que se hizo fue agregar en "last_cr = text.rfind('\n', 0, token.index)+1" ese +1 ya que el error era que siempre le faltaba sumar 1 mas en todas despues de la priemra linea, con eso fue solucionado, y no tuvo problema para de la peimra linea ya que la condición antes daba -1 y con el cambio daba 0 y por ese if garantizaba que si es negativo será 0.

A medida que se continuaba creando tokens y expresión regular para palabras reservadas, se dicidió consultar mas sobre la clase lexer; de seguro debia de tener algo relacionado con eso para indicar directamente de las palabras reservadas, y efectivamente de https://github.com/dabeaz/sly/blob/master/docs/sly.rst con un ejemplo de allí

ejemplo:

#--#
# calclex.py

from sly import Lexer

class CalcLexer(Lexer):
    # Set of reserved names (language keywords)
    reserved_words = { 'WHILE', 'IF', 'ELSE', 'PRINT' }

    # Set of token names.   This is always required
    tokens = {
        'NUMBER',
        'ID',
        'PLUS',
        'MINUS',
        'TIMES',
        'DIVIDE',
        'ASSIGN',
        'EQ',
        'LT',
        'LE',
        'GT',
        'GE',
        'NE',
        *reserved_words,
        }
	.
	.
	.
	
	@_(r'[a-zA-Z_][a-zA-Z0-9_]*')
    def ID(self, t):
        # Check if name matches a reserved word (change token type if true)
        if t.value.upper() in self.reserved_words:
            t.type = t.value.upper()
        return t

#--#

de este ejemplo se tomó ese funcionamiendo con las palabras reservadas y se adaptó para el "test léxico.py", tambien se encontró en la documentación sobre como ignorar, lo cual se hace colocando a la hora de definir la expresión regular del token ignore_nombretoken y asi las excluye automaticamente al hacer el lexer y finalmente en la clase se aclararo un poco mas del contenido de la entrega del léxico; el codigo completo quedó asi:

archivo "test léxico.py":

#--#
# -----------------------------------------------------------------------------
# calc.py
# -----------------------------------------------------------------------------

from sly import Lexer, Parser

class CalcLexer(Lexer):
	
	reserved_words = { 'BEGIN', 'CONST', 'END', 'IN', 'INOUT', 'MODULE', 'OUT', 'REG', 'TS', 'OC', 'TYPE', 'VAR', 'DIV', 'MOD', 'MUX', 'LATCH', 'SR', 'IF', 'THEN', 'ELSIF', 'FOR', 'DO' }
	
	tokens = {
		'identificador', 'INTEGER',  'FACTOR', 'DOSPUNTOSIGUAL', 'MENORIGUAL', 'MAYORIGUAL', 'FLECHADERECHA', 'DOBLEPUNTO', "DOSUNO", *reserved_words,
	}
	ignore = ' \t'
	
	literals = { '~', '&', '|', '^', '+', '-', '*', '=', '#', '<', '>', '(', ')', '[', ']', '{', '}', '.', ',', ';', ':' , "'", '!', '?'}
	
	#Tokens - simbolos compuestos
	DOBLEPUNTO = r'\.\.'#r'[.][.]'
	FLECHADERECHA = r'->'
	MAYORIGUAL = r'>='
	MENORIGUAL = r'<='
	DOSPUNTOSIGUAL = r':='
	
	# Tokens - otros
	#Tokens - operadores
	@_(r'\+')
	def PLUS(self, t):
		
		t.type = 'PLUS'      # Set token type to the expected literal
		return t
	
	#@_ es un llamado por parte d ela clase por su patron decorador
	@_(r'[a-zA-Z_][a-zA-Z0-9_]*')
	def identificador(self, t):
		#Control de palabras reservadas, o ma bien de priorizar check de expresión regular
		# Chec	k if name matches a reserved word (change token type if true)
		if t.value.upper() in self.reserved_words:
			t.type = t.value.upper()
		return t
	
	
	@_(r'\d+')#expresión regular que trabaja [0-9]
	def INTEGER(self, t):
		t.value = int(t.value)
		return t
	
	@_(r'\n+')
	def ignore_newline(self, t):
		self.lineno += t.value.count('\n')

	def error(self, value):
		print("Illegal character '%s'" % value[0])
		self.index += 1
	ignore_comment=r'\(\*[^(*]*[^*)]*\*\)'
		
	# Compute column.
	#     input is the input text string
	#     token is a token instance
	def getColumn(self, text, token):
		last_cr = text.rfind('\n', 0, token.index)+1
		#print("last_cr : {}".format(last_cr))#verificando valor de indexados previos
		if last_cr < 0:
			last_cr = 0
		column = (token.index - last_cr) + 1
		return column
	
if __name__ == '__main__':
	file=open("test.txt")
	data=""
	lexer = CalcLexer()
	LineNum=1
	ColumNum=1
	for linea in file:
		data+=linea
	print("Archivo recibido - contenido")
	print(data)
	for tok in lexer.tokenize(data):
		print("Linea {}, columna {}, indexado {}".format(tok.lineno, lexer.getColumn(data, tok), tok.index))
		print('tipo {} valor {}'.format(tok.type, tok.value))
#--#